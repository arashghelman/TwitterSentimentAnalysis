{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9e791523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from emoji import replace_emoji\n",
    "import re\n",
    "import logging\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "04bd42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "log_file = os.path.join(log_dir, f\"SentimentAnalysis_{timestamp}.log\")\n",
    "open(log_file, \"w\")\n",
    "\n",
    "logging.basicConfig(filename=log_file,\n",
    "                    format='%(asctime)s - %(message)s',\n",
    "                    filemode=\"w\",\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "7839c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sentiment Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "449b4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.option(\"header\", \"true\").csv(\"./dataset/train.csv\")\n",
    "train_df = train_df.withColumn(\"label\", (col(\"target\") / 4).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "9391f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text is None: return \"\"\n",
    "\n",
    "    text = replace_emoji(text, \"\")\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "\n",
    "    return text.lower().strip()\n",
    "\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "\n",
    "train_df = train_df.withColumn(\"clean_text\", clean_udf(col(\"text\")))\n",
    "train_df = train_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "075f5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer() \\\n",
    "    .setInputCol(\"clean_text\") \\\n",
    "    .setOutputCol(\"tokens\") \\\n",
    "    .setPattern(\"\\\\W+\") \\\n",
    "    .setGaps(True)\n",
    "\n",
    "remover = StopWordsRemover() \\\n",
    "    .setInputCol(\"tokens\") \\\n",
    "    .setOutputCol(\"filtered_text\")\n",
    "\n",
    "hashingTF = HashingTF() \\\n",
    "    .setInputCol(\"filtered_text\") \\\n",
    "    .setOutputCol(\"rawFeatures\") \\\n",
    "    .setNumFeatures(5000)\n",
    "\n",
    "idf = IDF() \\\n",
    "    .setInputCol(\"rawFeatures\") \\\n",
    "    .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "30c5fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preprocessing Time: 26.28s                                            \n"
     ]
    }
   ],
   "source": [
    "preprocessing_start = time()\n",
    "\n",
    "preprocessing_pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf])\n",
    "model = preprocessing_pipeline.fit(train_df)\n",
    "train_df = model.transform(train_df)\n",
    "\n",
    "preprocessing_time = time() - preprocessing_start\n",
    "logger.info(f\"Preprocessing Time: {preprocessing_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "67f9efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read.option(\"header\", \"true\").csv(\"./dataset/test.csv\")\n",
    "test_df = test_df.filter(test_df.target != \"2\")\n",
    "test_df = test_df.withColumn(\"clean_text\", clean_udf(col(\"text\")))\n",
    "test_df = test_df.withColumn(\"label\", (col(\"target\") / 4).cast(\"int\"))\n",
    "test_df = model.transform(test_df)\n",
    "test_df = test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "536f9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Naive Bayes Time: 13.00s - Accuracy: 0.81 - F1 Score: 0.80            \n"
     ]
    }
   ],
   "source": [
    "nb_start = time()\n",
    "\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"multinomial\")\n",
    "nb_model = nb.fit(train_df)\n",
    "predictions = nb_model.transform(test_df)\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "nb_time = time() - nb_start\n",
    "logger.info(f\"Naive Bayes Time: {nb_time:.2f}s - Accuracy: {accuracy:.2f} - F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "977b7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logistic Regression Time: 24.09s - Accuracy: 0.81 - F1 Score: 0.81    \n"
     ]
    }
   ],
   "source": [
    "lr_start = time()\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_df)\n",
    "predictions = lr_model.transform(test_df)\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "lr_time = time() - lr_start\n",
    "logger.info(f\"Logistic Regression Time: {lr_time:.2f}s - Accuracy: {accuracy:.2f} - F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "771f2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_1 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_6 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_4 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_2 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_5 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_0 to disk instead.\n",
      "25/05/08 14:23:10 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:10 WARN BlockManager: Persisting block rdd_253_3 to disk instead.\n",
      "25/05/08 14:23:20 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 1755.5 MiB so far)\n",
      "25/05/08 14:23:20 WARN BlockManager: Persisting block rdd_253_7 to disk instead.\n",
      "25/05/08 14:23:37 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 1755.5 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:41 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:43 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 1755.5 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:48 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:23:55 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:02 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:02 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:02 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:02 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:03 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:03 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:03 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:03 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_3 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_5 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_1 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_4 in memory! (computed 222.8 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_6 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_0 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_7 in memory! (computed 346.2 MiB so far)\n",
      "25/05/08 14:24:10 WARN MemoryStore: Not enough space to cache rdd_253_2 in memory! (computed 346.2 MiB so far)\n",
      "INFO:root:Random Forest Time: 92.43s - Accuracy: 0.60 - F1 Score: 0.57          \n"
     ]
    }
   ],
   "source": [
    "rf_start = time()\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=20, maxDepth=5)\n",
    "rfModel = rf.fit(train_df)\n",
    "predictions = rfModel.transform(test_df)\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "rf_time = time() - rf_start\n",
    "logger.info(f\"Random Forest Time: {rf_time:.2f}s - Accuracy: {accuracy:.2f} - F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 14:24:19 WARN BlockManager: Block rdd_253_5 could not be removed as it was not found on disk or in memory\n",
      "25/05/08 14:24:19 WARN BlockManager: Block rdd_253_1 could not be removed as it was not found on disk or in memory\n",
      "25/05/08 14:24:19 WARN BlockManager: Block rdd_253_0 could not be removed as it was not found on disk or in memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 14:24:19 WARN BlockManager: Block rdd_253_2 was not removed normally.\n",
      "java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@3a81d62 rejected from java.util.concurrent.ThreadPoolExecutor@d6fe367[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 495]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@4c52e95c rejected from java.util.concurrent.ThreadPoolExecutor@d6fe367[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 495]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
